{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-06 19:21:00.714754: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-06 19:21:01.295498: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-03-06 19:21:01.333978: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-06 19:21:01.334019: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-06 19:21:02.706929: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-06 19:21:02.707252: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-06 19:21:02.707260: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '.\\raw_data\\\\Brain-Tumor-Classification-DataSet-master\\\\Brain-Tumor-Classification-DataSet-master.zip\\\\Brain-Tumor-Classification-DataSet-master/glioma_tumor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 37\u001b[0m\n\u001b[1;32m     33\u001b[0m     y_test, y_val, y_train \u001b[39m=\u001b[39m y[:first_split], y[first_split:second_split], y[second_split:]\n\u001b[1;32m     35\u001b[0m     \u001b[39mreturn\u001b[39;00m X_train, y_train, X_val, y_val, X_test, y_test, num_classes\n\u001b[0;32m---> 37\u001b[0m X_train, y_train, X_val, y_val, X_test, y_test, num_classes \u001b[39m=\u001b[39m load_tumor_images()\n",
      "Cell \u001b[0;32mIn[3], line 11\u001b[0m, in \u001b[0;36mload_tumor_images\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m images \u001b[39m=\u001b[39m []\n\u001b[1;32m     10\u001b[0m \u001b[39mfor\u001b[39;00m (name, index) \u001b[39min\u001b[39;00m classes\u001b[39m.\u001b[39mitems():\n\u001b[0;32m---> 11\u001b[0m     curr_images \u001b[39m=\u001b[39m [elt \u001b[39mfor\u001b[39;00m elt \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39;49mlistdir(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(path, name))] \u001b[39m# This gets all images' names from all different folders\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     \u001b[39mfor\u001b[39;00m img_name \u001b[39min\u001b[39;00m tqdm(curr_images): \u001b[39m# Iterate over all names from curr_images\u001b[39;00m\n\u001b[1;32m     14\u001b[0m         path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(path, name, img_name) \u001b[39m# Get the path for every specific image\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '.\\raw_data\\\\Brain-Tumor-Classification-DataSet-master\\\\Brain-Tumor-Classification-DataSet-master.zip\\\\Brain-Tumor-Classification-DataSet-master/glioma_tumor'"
     ]
    }
   ],
   "source": [
    "def load_tumor_images():\n",
    "    path= \".\\\\raw_data\\Brain-Tumor-Classification-DataSet-master\\Brain-Tumor-Classification-DataSet-master.zip\\Brain-Tumor-Classification-DataSet-master\"\n",
    "    # Abs -> ~/code/CatalinaGroba/tumor_classification/...\n",
    "    # Relative -> ./\n",
    "    \n",
    "    classes = {'glioma_tumor':0,'meningioma_tumor':1,'pituitary_tumor':2,'no_tumor':3}\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    images = []\n",
    "    for (name, index) in classes.items():\n",
    "        curr_images = [elt for elt in os.listdir(os.path.join(path, name))] # This gets all images' names from all different folders\n",
    "\n",
    "        for img_name in tqdm(curr_images): # Iterate over all names from curr_images\n",
    "            path = os.path.join(path, name, img_name) # Get the path for every specific image\n",
    "            if os.path.exists(path): # If correct path\n",
    "                image = Image.open(path)\n",
    "                image = image.resize((256, 256))\n",
    "                images.append(np.array(image)) # Open, resize and append as array to images\n",
    "                labels.append(index)\n",
    "            path= \"./raw_data/Training\"\n",
    "\n",
    "    X = np.array(images)\n",
    "    num_classes = len(set(labels))\n",
    "    y = to_categorical(labels, num_classes)\n",
    "\n",
    "    # Finally we shuffle:\n",
    "    p = np.random.permutation(len(X))\n",
    "    X, y = X[p], y[p]\n",
    "\n",
    "    first_split = int(len(images) /6.)\n",
    "    second_split = first_split + int(len(images) * 0.2)\n",
    "    X_test, X_val, X_train = X[:first_split], X[first_split:second_split], X[second_split:]\n",
    "    y_test, y_val, y_train = y[:first_split], y[first_split:second_split], y[second_split:]\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, num_classes\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, num_classes = load_tumor_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "\n",
    "def load_model():\n",
    "    \n",
    "    model = EfficientNetB0(weights='imagenet',include_top=False,input_shape=X_train[0].shape)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer = 'Adam', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_nontrainable_layers(model):\n",
    "    \n",
    "    model.trainable = False\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = set_nontrainable_layers(model)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def add_last_layers(model):\n",
    "    '''Take a pre-trained model, set its parameters as non-trainable, and add additional trainable layers on top'''\n",
    "    # $CHALLENGIFY_BEGIN\n",
    "    base_model = set_nontrainable_layers(model)\n",
    "    flatten_layer = layers.Flatten()\n",
    "    dense_layer = layers.Dense(500, activation='relu')\n",
    "    prediction_layer = layers.Dense(3, activation='softmax')\n",
    "    \n",
    "    \n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        flatten_layer,\n",
    "        dense_layer,\n",
    "        prediction_layer\n",
    "    ])\n",
    "    # $CHALLENGIFY_END\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = add_last_layers(model)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "def build_model():\n",
    "    # $CHALLENGIFY_BEGIN    \n",
    "    model = load_model()\n",
    "    model = add_last_layers(model)\n",
    "    \n",
    "    opt = optimizers.Adam(learning_rate=1e-4)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "es = EarlyStopping(monitor = 'val_accuracy', \n",
    "                   mode = 'max', \n",
    "                   patience = 5, \n",
    "                   verbose = 1, \n",
    "                   restore_best_weights = True)\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_val, y_val), \n",
    "                    epochs=50, \n",
    "                    batch_size=16, \n",
    "                    callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = model.evaluate(X_test, y_test)\n",
    "\n",
    "test_accuracy_vgg = evaluation[-1]\n",
    "\n",
    "\n",
    "print(f\"test_accuracy_vgg = {round(test_accuracy_vgg,2)*100} %\")\n",
    "\n",
    "print(f\"test_accuracy = {round(test_accuracy,2)*100} %\")\n",
    "\n",
    "print(f'Chance level: {1./num_classes*100:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction():\n",
    "    pred = model.predict(X_test)\n",
    "    return pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
